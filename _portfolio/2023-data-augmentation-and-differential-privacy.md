---
title: "How Does Data Augmentation Affect Differential Privacy in Deep Learning?"
excerpt: "Final project for my *Neural Networks and Deep Learning* course"
collection: portfolio
permalink: /portfolio/data-augmentation-and-differential-privacy/
---

Deep learning often adopts data augmentation as an essential and efficient technique to generate new training examples from existing data to improve the model robustness and generalization. Differential privacy is a technique used to preserve the privacy of individual data points while releasing statistical information about a dataset. In this work, we study the relationship between data augmentation and differential privacy in deep learning for image and text classification. We found that although data augmentation has a negative effect on the performance of models trained with differential privacy, it improves the model robustness against membership inference attacks.

The code is in GitHub [How Does Data Augmentation Affect Differential Privacy in Deep Learning?](https://github.com/davidguzmanr/Data-augmentation-with-differential-privacy).

<html>
  <head>
    <title>How Does Data Augmentation Affect Differential Privacy in Deep Learning?</title>
  </head>
  <body>
    <h1>How Does Data Augmentation Affect Differential Privacy in Deep Learning?</h1>
    <iframe src="https://davidguzmanr.github.io/files/How_Does_Data_Augmentation_Affect_Differential_Privacy_in_Deep_Learning.pdf" width="100%" height="500px">
    </iframe>
  </body>
</html>
